---
layout: archive
permalink: /publications/
author_profile: true
---

<head>
<link rel="stylesheet" type="text/css" href="/assets/css/paper.css" />
</head>

Publications
=======

<hr width="100%"/>
<div class="paper">
<div class="pimg"> <img src="/img_content/scs.png" width="200" height="140"></div>
<div class="ptitle"> Complex sequential understanding through the awareness of spatial and temporal concepts</div>
<div class="pauthors"> <b>Bo Pang</b>, Kaiwen Zha, Hanwen Cao, Jiajun Tang, Minghui Yu, Cewu Lu</div>
<div class="pvenue">
<p>Nature Machine Intelligence</p>
<p>
[<a href="https://www.nature.com/articles/s42256-020-0168-3">paper</a>]
[<a href="https://rdcu.be/b3OIN">Read-Only Link</a>]
</p>
</div>
</div>

<hr width="100%"/>
<div class="paper">
<div class="pimg"> <img src="/img_content/tubetk.png" width="200" height="140"></div>
<div class="ptitle"> TubeTK: Adopting Tubes to Track Multi-Object in a One-Step Training Model</div>
<div class="pauthors"> <b>Bo Pang</b>, Yizhuo Li, Yifan Zhang, Muchen Li, Cewu Lu</div>
<div class="pvenue">
<p>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020 (<font color="red"><b>oral</b></font>)</p>
<p>[<a href="https://bopang1996.github.io/posts/2020/04/tubeTKpaper/">paper</a>]
   [<a href="https://github.com/BoPang1996/TubeTK">code</a>]</p>
</div>
</div>

<hr width="100%"/>
<div class="paper">
<div class="pimg"> <img src="/img_content/vaad.png" width="200" height="140"></div>
<div class="ptitle">Further Understanding Videos through Adverbs: A New Video Task</div>
<div class="pauthors"> <b>Bo Pang</b>, Kaiwen Zha, Yifan Zhang, Cewu Lu</div>
<div class="pvenue">
<p>AAAI Conference on Artificial Intelligence (AAAI), 2020</p>
<p>[<a href="https://www.aaai.org/Papers/AAAI/2020GB/AAAI-PangB.53.pdf">paper</a>]</p>
</div>
</div>


<hr width="100%"/>
<div class="paper">
<div class="pimg"> <img src="/img_content/deeprnn.png" width="200" height="140"></div>
<div class="ptitle"> Deep RNN Framework for Visual Sequential Applications</div>
<div class="pauthors"> <b>Bo Pang</b>, Kaiwen Zha, Hanwen Cao, Chen Shi, Cewu Lu</div>
<div class="pvenue">
<p>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019</p>
<p>[<a href="https://zpascal.net/cvpr2019/Pang_Deep_RNN_Framework_for_Visual_Sequential_Applications_CVPR_2019_paper.pdf">paper</a>]
   [<a href="https://github.com/BoPang1996/Deep-RNN-Framework">Code</a>]</p>
</div>
</div>

<hr width="100%"/>
<div class="paper">
<div class="pimg"> <img src="/img_content/adha.png" width="200" height="140"></div>
<div class="ptitle"> Human Action Adverb Recognition: ADHA Dataset and A Three-Stream Hybrid Model</div>
<div class="pauthors"> <b>Bo Pang</b>, Kaiwen Zha, Cewu Lu</div>
<div class="pvenue">
<p>IEEE Conference on Computer Vision and Pattern Recognition Workshops(CVPRW), 2018</p>
<p>[<a href="http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w48/Pang_Human_Action_Adverb_CVPR_2018_paper.pdf">paper</a>]</p>
</div>
</div>

<hr width="100%"/>

Pre-Print
======
<hr width="100%"/>
<div class="paper">
<div class="pimg"> <img src="/img_content/tdaf.png" width="200" height="140"></div>
<div class="ptitle"> TDAF: Top-Down Attention Framework for Vision Tasks</div>
<div class="pauthors"> <b>Bo Pang</b>, Yizhuo Li, Jiefeng Li, Muchen Li, Hanwen Cao, Cewu Lu</div>
<div class="pvenue">
<p>Submitted to ECCV, 2020</p>
<p>[paper]</p>
</div>
</div>

<hr width="100%"/>
<div class="paper">
<div class="pimg"> <img src="/img_content/alphaction.png" width="200" height="140"></div>
<div class="ptitle">Asynchronous Interaction Aggregation for Action Detection</div>
<div class="pauthors">Jiajun Tang, Jin Xia, Xinzhi Mu, <b>Bo Pang</b>, Cewu Lu</div>
<div class="pvenue">
<p>Submitted to ECCV, 2020</p>
<p>[<a href="https://arxiv.org/abs/2004.07485">paper</a>]
   [<a href="https://github.com/MVIG-SJTU/AlphAction">code</a>]
</p>
</div>
</div>

